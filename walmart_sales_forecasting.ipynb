{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment: Walmart Sales Forecasting\n",
        "\n",
        "This notebook builds a full demand-forecasting pipeline on `walmart_sales.csv` with:\n",
        "- Statistical demand equation estimation and parametric tests\n",
        "- Tree-based models: Random Forest, Extra Trees, XGBoost\n",
        "- Ensemble model: Voting Regressor\n",
        "- Visual diagnostics, heatmaps, and forecast quality plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d96f08ed",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HAS_XGB = True\n",
            "Data path exists = True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['MPLCONFIGDIR'] = '/tmp/mpl'\n",
        "os.makedirs('/tmp/mpl', exist_ok=True)\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, VotingRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.base import clone\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "from statsmodels.stats.stattools import durbin_watson, jarque_bera\n",
        "from statsmodels.tsa.stattools import adfuller, kpss, zivot_andrews\n",
        "from statsmodels.tools.sm_exceptions import InterpolationWarning\n",
        "\n",
        "warnings.filterwarnings('ignore', category=InterpolationWarning)\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    HAS_XGB = True\n",
        "except Exception:\n",
        "    HAS_XGB = False\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_context('notebook')\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "PROJECT_ROOT = Path('/Users/panshulaj/Documents/front')\n",
        "DATA_PATH = PROJECT_ROOT / 'dashboard' / 'data' / 'walmart_sales.csv'\n",
        "OUT_DIR = PROJECT_ROOT / 'outputs'\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('HAS_XGB =', HAS_XGB)\n",
        "print('Data path exists =', DATA_PATH.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "855dbe46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (6435, 8)\n",
            "Columns: ['Store', 'Date', 'Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
            "\n",
            "Missing values by column:\n",
            "Store           0\n",
            "Date            0\n",
            "Weekly_Sales    0\n",
            "Holiday_Flag    0\n",
            "Temperature     0\n",
            "Fuel_Price      0\n",
            "CPI             0\n",
            "Unemployment    0\n",
            "dtype: int64\n",
            "\n",
            "Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Store</th>\n",
              "      <td>6435.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>12.988182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <td>6435</td>\n",
              "      <td>2011-06-17 00:00:00</td>\n",
              "      <td>2010-02-05 00:00:00</td>\n",
              "      <td>2010-10-08 00:00:00</td>\n",
              "      <td>2011-06-17 00:00:00</td>\n",
              "      <td>2012-02-24 00:00:00</td>\n",
              "      <td>2012-10-26 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <td>6435.0</td>\n",
              "      <td>1046964.877562</td>\n",
              "      <td>209986.25</td>\n",
              "      <td>553350.105</td>\n",
              "      <td>960746.04</td>\n",
              "      <td>1420158.66</td>\n",
              "      <td>3818686.45</td>\n",
              "      <td>564366.622054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Holiday_Flag</th>\n",
              "      <td>6435.0</td>\n",
              "      <td>0.06993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.255049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Temperature</th>\n",
              "      <td>6435.0</td>\n",
              "      <td>60.663782</td>\n",
              "      <td>-2.06</td>\n",
              "      <td>47.46</td>\n",
              "      <td>62.67</td>\n",
              "      <td>74.94</td>\n",
              "      <td>100.14</td>\n",
              "      <td>18.444933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fuel_Price</th>\n",
              "      <td>6435.0</td>\n",
              "      <td>3.358607</td>\n",
              "      <td>2.472</td>\n",
              "      <td>2.933</td>\n",
              "      <td>3.445</td>\n",
              "      <td>3.735</td>\n",
              "      <td>4.468</td>\n",
              "      <td>0.45902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CPI</th>\n",
              "      <td>6435.0</td>\n",
              "      <td>171.578394</td>\n",
              "      <td>126.064</td>\n",
              "      <td>131.735</td>\n",
              "      <td>182.616521</td>\n",
              "      <td>212.743293</td>\n",
              "      <td>227.232807</td>\n",
              "      <td>39.356712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unemployment</th>\n",
              "      <td>6435.0</td>\n",
              "      <td>7.999151</td>\n",
              "      <td>3.879</td>\n",
              "      <td>6.891</td>\n",
              "      <td>7.874</td>\n",
              "      <td>8.622</td>\n",
              "      <td>14.313</td>\n",
              "      <td>1.875885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               count                 mean                  min  \\\n",
              "Store         6435.0                 23.0                  1.0   \n",
              "Date            6435  2011-06-17 00:00:00  2010-02-05 00:00:00   \n",
              "Weekly_Sales  6435.0       1046964.877562            209986.25   \n",
              "Holiday_Flag  6435.0              0.06993                  0.0   \n",
              "Temperature   6435.0            60.663782                -2.06   \n",
              "Fuel_Price    6435.0             3.358607                2.472   \n",
              "CPI           6435.0           171.578394              126.064   \n",
              "Unemployment  6435.0             7.999151                3.879   \n",
              "\n",
              "                              25%                  50%                  75%  \\\n",
              "Store                        12.0                 23.0                 34.0   \n",
              "Date          2010-10-08 00:00:00  2011-06-17 00:00:00  2012-02-24 00:00:00   \n",
              "Weekly_Sales           553350.105            960746.04           1420158.66   \n",
              "Holiday_Flag                  0.0                  0.0                  0.0   \n",
              "Temperature                 47.46                62.67                74.94   \n",
              "Fuel_Price                  2.933                3.445                3.735   \n",
              "CPI                       131.735           182.616521           212.743293   \n",
              "Unemployment                6.891                7.874                8.622   \n",
              "\n",
              "                              max            std  \n",
              "Store                        45.0      12.988182  \n",
              "Date          2012-10-26 00:00:00            NaN  \n",
              "Weekly_Sales           3818686.45  564366.622054  \n",
              "Holiday_Flag                  1.0       0.255049  \n",
              "Temperature                100.14      18.444933  \n",
              "Fuel_Price                  4.468        0.45902  \n",
              "CPI                    227.232807      39.356712  \n",
              "Unemployment               14.313       1.875885  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and inspect data\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
        "df = df.dropna(subset=['Date']).copy()\n",
        "df = df.sort_values(['Store', 'Date']).reset_index(drop=True)\n",
        "\n",
        "print('Shape:', df.shape)\n",
        "print('Columns:', list(df.columns))\n",
        "print()\n",
        "print('Missing values by column:')\n",
        "print(df.isna().sum())\n",
        "print()\n",
        "print('Date range:', df['Date'].min(), 'to', df['Date'].max())\n",
        "\n",
        "summary = df.describe(include='all').T\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74afef03",
      "metadata": {},
      "source": [
        "## Exploratory Analysis\n",
        "We visualize the overall series behavior, feature correlations, and seasonality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "00a6cf69",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate trend\n",
        "weekly_total = df.groupby('Date', as_index=False)['Weekly_Sales'].sum()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "axes[0, 0].plot(weekly_total['Date'], weekly_total['Weekly_Sales'], color='#1f77b4')\n",
        "axes[0, 0].set_title('Total Weekly Sales Over Time')\n",
        "axes[0, 0].set_xlabel('Date')\n",
        "axes[0, 0].set_ylabel('Weekly Sales')\n",
        "\n",
        "sns.histplot(df['Weekly_Sales'], bins=50, kde=True, ax=axes[0, 1], color='#2ca02c')\n",
        "axes[0, 1].set_title('Distribution of Weekly Sales')\n",
        "\n",
        "corr_cols = ['Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
        "corr = df[corr_cols].corr()\n",
        "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Correlation Heatmap')\n",
        "\n",
        "monthly = df.assign(Month=df['Date'].dt.month).groupby('Month', as_index=False)['Weekly_Sales'].mean()\n",
        "sns.barplot(data=monthly, x='Month', y='Weekly_Sales', ax=axes[1, 1], palette='viridis')\n",
        "axes[1, 1].set_title('Average Sales by Month')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUT_DIR / 'eda_overview.png', dpi=160)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58cf43f3",
      "metadata": {},
      "source": [
        "## Stationarity Checks (Non-Stationarity vs Log-Stationarity)\n",
        "We test stationarity using both:\n",
        "- ADF (null: non-stationary / unit root)\n",
        "- KPSS (null: stationary)\n",
        "- Zivot-Andrews (unit root with one endogenous structural break)\n",
        "\n",
        "This section checks raw sales, log-sales, and differenced variants.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d4f91694",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Series</th>\n",
              "      <th>n_obs</th>\n",
              "      <th>ADF_stat_c</th>\n",
              "      <th>ADF_p_c</th>\n",
              "      <th>ADF_stationary_at_5pct_c</th>\n",
              "      <th>ADF_stat_ct</th>\n",
              "      <th>ADF_p_ct</th>\n",
              "      <th>ADF_stationary_at_5pct_ct</th>\n",
              "      <th>KPSS_stat_c</th>\n",
              "      <th>KPSS_p_c</th>\n",
              "      <th>KPSS_stationary_at_5pct_c</th>\n",
              "      <th>KPSS_stat_ct</th>\n",
              "      <th>KPSS_p_ct</th>\n",
              "      <th>KPSS_stationary_at_5pct_ct</th>\n",
              "      <th>ZA_stat</th>\n",
              "      <th>ZA_p</th>\n",
              "      <th>ZA_stationary_at_5pct</th>\n",
              "      <th>Consensus_stationary_at_5pct</th>\n",
              "      <th>KPSS_boundary_note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aggregate Weekly_Sales (level)</td>\n",
              "      <td>143</td>\n",
              "      <td>-5.90830</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>-5.89924</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.04889</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.03712</td>\n",
              "      <td>0.10000</td>\n",
              "      <td>True</td>\n",
              "      <td>-6.60929</td>\n",
              "      <td>0.00099</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aggregate diff(Weekly_Sales)</td>\n",
              "      <td>142</td>\n",
              "      <td>-6.69947</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>-6.67356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.11635</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.11567</td>\n",
              "      <td>0.10000</td>\n",
              "      <td>True</td>\n",
              "      <td>-7.39064</td>\n",
              "      <td>0.00097</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aggregate diff(log(Weekly_Sales))</td>\n",
              "      <td>142</td>\n",
              "      <td>-6.74706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>-6.72040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.14284</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.14006</td>\n",
              "      <td>0.06099</td>\n",
              "      <td>True</td>\n",
              "      <td>-7.36355</td>\n",
              "      <td>0.00097</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aggregate log(Weekly_Sales)</td>\n",
              "      <td>143</td>\n",
              "      <td>-6.33283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>-6.33579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.05315</td>\n",
              "      <td>0.1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.03477</td>\n",
              "      <td>0.10000</td>\n",
              "      <td>True</td>\n",
              "      <td>-7.07186</td>\n",
              "      <td>0.00098</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Series  n_obs  ADF_stat_c  ADF_p_c  \\\n",
              "0     Aggregate Weekly_Sales (level)    143    -5.90830      0.0   \n",
              "1       Aggregate diff(Weekly_Sales)    142    -6.69947      0.0   \n",
              "2  Aggregate diff(log(Weekly_Sales))    142    -6.74706      0.0   \n",
              "3        Aggregate log(Weekly_Sales)    143    -6.33283      0.0   \n",
              "\n",
              "   ADF_stationary_at_5pct_c  ADF_stat_ct  ADF_p_ct  ADF_stationary_at_5pct_ct  \\\n",
              "0                      True     -5.89924       0.0                       True   \n",
              "1                      True     -6.67356       0.0                       True   \n",
              "2                      True     -6.72040       0.0                       True   \n",
              "3                      True     -6.33579       0.0                       True   \n",
              "\n",
              "   KPSS_stat_c  KPSS_p_c  KPSS_stationary_at_5pct_c  KPSS_stat_ct  KPSS_p_ct  \\\n",
              "0      0.04889       0.1                       True       0.03712    0.10000   \n",
              "1      0.11635       0.1                       True       0.11567    0.10000   \n",
              "2      0.14284       0.1                       True       0.14006    0.06099   \n",
              "3      0.05315       0.1                       True       0.03477    0.10000   \n",
              "\n",
              "   KPSS_stationary_at_5pct_ct  ZA_stat     ZA_p  ZA_stationary_at_5pct  \\\n",
              "0                        True -6.60929  0.00099                   True   \n",
              "1                        True -7.39064  0.00097                   True   \n",
              "2                        True -7.36355  0.00097                   True   \n",
              "3                        True -7.07186  0.00098                   True   \n",
              "\n",
              "   Consensus_stationary_at_5pct  KPSS_boundary_note  \n",
              "0                          True                True  \n",
              "1                          True                True  \n",
              "2                          True                True  \n",
              "3                          True                True  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Aggregate stationarity checks (robust version)\n",
        "\n",
        "agg = df.groupby('Date', as_index=False)['Weekly_Sales'].sum().sort_values('Date')\n",
        "agg['log_sales'] = np.log(agg['Weekly_Sales'])\n",
        "agg['diff_sales'] = agg['Weekly_Sales'].diff()\n",
        "agg['diff_log_sales'] = agg['log_sales'].diff()\n",
        "\n",
        "def stationarity_test(series, name):\n",
        "    s = pd.Series(series).dropna()\n",
        "    out = {'Series': name, 'n_obs': int(len(s))}\n",
        "    adf_stat, adf_p, *_ = adfuller(s, regression='c', autolag='AIC')\n",
        "    out['ADF_stat_c'] = adf_stat\n",
        "    out['ADF_p_c'] = adf_p\n",
        "    out['ADF_stationary_at_5pct_c'] = adf_p < 0.05\n",
        "    adf_stat_t, adf_p_t, *_ = adfuller(s, regression='ct', autolag='AIC')\n",
        "    out['ADF_stat_ct'] = adf_stat_t\n",
        "    out['ADF_p_ct'] = adf_p_t\n",
        "    out['ADF_stationary_at_5pct_ct'] = adf_p_t < 0.05\n",
        "    try:\n",
        "        kpss_stat_c, kpss_p_c, *_ = kpss(s, regression='c', nlags='auto')\n",
        "        out['KPSS_stat_c'] = kpss_stat_c\n",
        "        out['KPSS_p_c'] = kpss_p_c\n",
        "        out['KPSS_stationary_at_5pct_c'] = kpss_p_c > 0.05\n",
        "    except Exception:\n",
        "        out['KPSS_stat_c'] = np.nan\n",
        "        out['KPSS_p_c'] = np.nan\n",
        "        out['KPSS_stationary_at_5pct_c'] = np.nan\n",
        "    try:\n",
        "        kpss_stat_t, kpss_p_t, *_ = kpss(s, regression='ct', nlags='auto')\n",
        "        out['KPSS_stat_ct'] = kpss_stat_t\n",
        "        out['KPSS_p_ct'] = kpss_p_t\n",
        "        out['KPSS_stationary_at_5pct_ct'] = kpss_p_t > 0.05\n",
        "    except Exception:\n",
        "        out['KPSS_stat_ct'] = np.nan\n",
        "        out['KPSS_p_ct'] = np.nan\n",
        "        out['KPSS_stationary_at_5pct_ct'] = np.nan\n",
        "    try:\n",
        "        za_stat, za_p, *_ = zivot_andrews(s, regression='ct', autolag='AIC')\n",
        "        out['ZA_stat'] = za_stat\n",
        "        out['ZA_p'] = za_p\n",
        "        out['ZA_stationary_at_5pct'] = za_p < 0.05\n",
        "    except Exception:\n",
        "        out['ZA_stat'] = np.nan\n",
        "        out['ZA_p'] = np.nan\n",
        "        out['ZA_stationary_at_5pct'] = np.nan\n",
        "    out['Consensus_stationary_at_5pct'] = bool(\n",
        "        out['ADF_stationary_at_5pct_c']\n",
        "        and out['ADF_stationary_at_5pct_ct']\n",
        "        and out['KPSS_stationary_at_5pct_c']\n",
        "        and out['KPSS_stationary_at_5pct_ct']\n",
        "        and (out['ZA_stationary_at_5pct'] if not pd.isna(out['ZA_stationary_at_5pct']) else True)\n",
        "    )\n",
        "    out['KPSS_boundary_note'] = bool(\n",
        "        (not pd.isna(out['KPSS_p_c']) and float(out['KPSS_p_c']) in (0.1, 0.01))\n",
        "        or (not pd.isna(out['KPSS_p_ct']) and float(out['KPSS_p_ct']) in (0.1, 0.01))\n",
        "    )\n",
        "    return out\n",
        "\n",
        "stationarity_results = pd.DataFrame([\n",
        "    stationarity_test(agg['Weekly_Sales'], 'Aggregate Weekly_Sales (level)'),\n",
        "    stationarity_test(agg['log_sales'], 'Aggregate log(Weekly_Sales)'),\n",
        "    stationarity_test(agg['diff_sales'], 'Aggregate diff(Weekly_Sales)'),\n",
        "    stationarity_test(agg['diff_log_sales'], 'Aggregate diff(log(Weekly_Sales))')\n",
        "]).sort_values('Series').reset_index(drop=True)\n",
        "\n",
        "for c in ['ADF_stat_c', 'ADF_p_c', 'ADF_stat_ct', 'ADF_p_ct', 'KPSS_stat_c', 'KPSS_p_c', 'KPSS_stat_ct', 'KPSS_p_ct', 'ZA_stat', 'ZA_p']:\n",
        "    stationarity_results[c] = stationarity_results[c].map(lambda v: np.nan if pd.isna(v) else float(f'{v:.5f}'))\n",
        "\n",
        "stationarity_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "39ca0931",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Series</th>\n",
              "      <th>Stores_tested</th>\n",
              "      <th>ADF_stationary_%</th>\n",
              "      <th>KPSS_stationary_%</th>\n",
              "      <th>ZA_stationary_%</th>\n",
              "      <th>Rolling_ADF_pass_%</th>\n",
              "      <th>Consensus_stationary_%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Store-level Weekly_Sales (level)</td>\n",
              "      <td>45</td>\n",
              "      <td>84.44</td>\n",
              "      <td>62.22</td>\n",
              "      <td>75.56</td>\n",
              "      <td>73.33</td>\n",
              "      <td>48.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Store-level diff(Weekly_Sales)</td>\n",
              "      <td>45</td>\n",
              "      <td>100.00</td>\n",
              "      <td>97.78</td>\n",
              "      <td>91.11</td>\n",
              "      <td>97.78</td>\n",
              "      <td>88.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Store-level diff(log(Weekly_Sales))</td>\n",
              "      <td>45</td>\n",
              "      <td>100.00</td>\n",
              "      <td>93.33</td>\n",
              "      <td>95.56</td>\n",
              "      <td>95.56</td>\n",
              "      <td>84.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Store-level log(Weekly_Sales)</td>\n",
              "      <td>45</td>\n",
              "      <td>77.78</td>\n",
              "      <td>62.22</td>\n",
              "      <td>66.67</td>\n",
              "      <td>73.33</td>\n",
              "      <td>42.22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Series  Stores_tested  ADF_stationary_%  \\\n",
              "0     Store-level Weekly_Sales (level)             45             84.44   \n",
              "1       Store-level diff(Weekly_Sales)             45            100.00   \n",
              "2  Store-level diff(log(Weekly_Sales))             45            100.00   \n",
              "3        Store-level log(Weekly_Sales)             45             77.78   \n",
              "\n",
              "   KPSS_stationary_%  ZA_stationary_%  Rolling_ADF_pass_%  \\\n",
              "0              62.22            75.56               73.33   \n",
              "1              97.78            91.11               97.78   \n",
              "2              93.33            95.56               95.56   \n",
              "3              62.22            66.67               73.33   \n",
              "\n",
              "   Consensus_stationary_%  \n",
              "0                   48.89  \n",
              "1                   88.89  \n",
              "2                   84.44  \n",
              "3                   42.22  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Per-store summary with rolling-window stability score\n",
        "\n",
        "def rolling_adf_pass_fraction(s, window=52, step=4):\n",
        "    s = pd.Series(s).dropna().reset_index(drop=True)\n",
        "    if len(s) < window:\n",
        "        return np.nan\n",
        "    total = 0\n",
        "    passed = 0\n",
        "    for start in range(0, len(s) - window + 1, step):\n",
        "        win = s.iloc[start:start + window]\n",
        "        if len(win) < 20:\n",
        "            continue\n",
        "        try:\n",
        "            p = adfuller(win, regression='c', autolag='AIC')[1]\n",
        "            passed += int(p < 0.05)\n",
        "            total += 1\n",
        "        except Exception:\n",
        "            continue\n",
        "    return (passed / total) if total else np.nan\n",
        "\n",
        "def per_store_stationarity(col_name, use_log=False, use_diff=False, rolling_threshold=0.70):\n",
        "    rows = []\n",
        "    for store, g in df[['Store', 'Date', 'Weekly_Sales']].sort_values(['Store', 'Date']).groupby('Store'):\n",
        "        s = g['Weekly_Sales'].copy()\n",
        "        if use_log:\n",
        "            s = np.log(s)\n",
        "        if use_diff:\n",
        "            s = s.diff()\n",
        "        s = s.dropna()\n",
        "        if len(s) < 20:\n",
        "            continue\n",
        "        try:\n",
        "            adf_p = adfuller(s, autolag='AIC')[1]\n",
        "        except Exception:\n",
        "            adf_p = np.nan\n",
        "        try:\n",
        "            kpss_p = kpss(s, regression='c', nlags='auto')[1]\n",
        "        except Exception:\n",
        "            kpss_p = np.nan\n",
        "        try:\n",
        "            za_p = zivot_andrews(s, regression='ct', autolag='AIC')[1]\n",
        "        except Exception:\n",
        "            za_p = np.nan\n",
        "        rolling_share = rolling_adf_pass_fraction(s)\n",
        "        rows.append({\n",
        "            'Store': store,\n",
        "            'ADF_p': adf_p,\n",
        "            'KPSS_p': kpss_p,\n",
        "            'ZA_p': za_p,\n",
        "            'Rolling_ADF_share': rolling_share,\n",
        "        })\n",
        "    res = pd.DataFrame(rows)\n",
        "    consensus = (\n",
        "        (res['ADF_p'] < 0.05)\n",
        "        & (res['KPSS_p'] > 0.05)\n",
        "        & ((res['ZA_p'] < 0.05) | res['ZA_p'].isna())\n",
        "        & (res['Rolling_ADF_share'] >= rolling_threshold)\n",
        "    )\n",
        "    return {\n",
        "        'Series': col_name,\n",
        "        'Stores_tested': int(len(res)),\n",
        "        'ADF_stationary_%': float((res['ADF_p'] < 0.05).mean() * 100),\n",
        "        'KPSS_stationary_%': float((res['KPSS_p'] > 0.05).mean() * 100),\n",
        "        'ZA_stationary_%': float((res['ZA_p'] < 0.05).mean() * 100),\n",
        "        'Rolling_ADF_pass_%': float((res['Rolling_ADF_share'] >= rolling_threshold).mean() * 100),\n",
        "        'Consensus_stationary_%': float(consensus.mean() * 100),\n",
        "    }\n",
        "\n",
        "store_stationarity_summary = pd.DataFrame([\n",
        "    per_store_stationarity('Store-level Weekly_Sales (level)', use_log=False, use_diff=False),\n",
        "    per_store_stationarity('Store-level log(Weekly_Sales)', use_log=True, use_diff=False),\n",
        "    per_store_stationarity('Store-level diff(Weekly_Sales)', use_log=False, use_diff=True),\n",
        "    per_store_stationarity('Store-level diff(log(Weekly_Sales))', use_log=True, use_diff=True),\n",
        "]).sort_values('Series').reset_index(drop=True)\n",
        "\n",
        "for c in ['ADF_stationary_%', 'KPSS_stationary_%', 'ZA_stationary_%', 'Rolling_ADF_pass_%', 'Consensus_stationary_%']:\n",
        "    store_stationarity_summary[c] = store_stationarity_summary[c].map(lambda x: float(f'{x:.2f}'))\n",
        "\n",
        "store_stationarity_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a5355444",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visual rolling mean/std diagnostics for aggregate level/log series\n",
        "\n",
        "roll_window = 12\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 8))\n",
        "\n",
        "for i, (series, title) in enumerate([\n",
        "    (agg['Weekly_Sales'], 'Aggregate Weekly_Sales (level)'),\n",
        "    (agg['log_sales'], 'Aggregate log(Weekly_Sales)')\n",
        "]):\n",
        "    r = i\n",
        "    axes[r, 0].plot(agg['Date'], series, label='Series')\n",
        "    axes[r, 0].plot(agg['Date'], series.rolling(roll_window).mean(), label='Rolling mean (12)', linestyle='--')\n",
        "    axes[r, 0].set_title(f'{title} and Rolling Mean')\n",
        "    axes[r, 0].legend()\n",
        "\n",
        "    axes[r, 1].plot(agg['Date'], series.rolling(roll_window).std(), color='tab:orange')\n",
        "    axes[r, 1].set_title(f'{title} Rolling Std (12)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUT_DIR / 'stationarity_diagnostics.png', dpi=160)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "899da8de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows dropped due to lag/rolling features: 360\n",
            "Modeling shape: (6075, 33)\n",
            "Log features added: ['ln_Weekly_Sales', 'ln_Temperature', 'ln_Fuel_Price', 'ln_CPI', 'ln_Unemployment', 'ln_sales_lag_1', 'ln_sales_lag_2', 'ln_sales_lag_4', 'ln_sales_lag_8', 'ln_sales_roll4_mean', 'ln_sales_roll4_std']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Holiday_Flag</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>...</th>\n",
              "      <th>ln_Temperature</th>\n",
              "      <th>ln_Fuel_Price</th>\n",
              "      <th>ln_CPI</th>\n",
              "      <th>ln_Unemployment</th>\n",
              "      <th>ln_sales_lag_1</th>\n",
              "      <th>ln_sales_lag_2</th>\n",
              "      <th>ln_sales_lag_4</th>\n",
              "      <th>ln_sales_lag_8</th>\n",
              "      <th>ln_sales_roll4_mean</th>\n",
              "      <th>ln_sales_roll4_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-04-02</td>\n",
              "      <td>1594968.28</td>\n",
              "      <td>0</td>\n",
              "      <td>62.27</td>\n",
              "      <td>2.719</td>\n",
              "      <td>210.820450</td>\n",
              "      <td>7.808</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.131480</td>\n",
              "      <td>1.000264</td>\n",
              "      <td>5.351007</td>\n",
              "      <td>2.055149</td>\n",
              "      <td>14.155142</td>\n",
              "      <td>14.202483</td>\n",
              "      <td>14.256862</td>\n",
              "      <td>14.312455</td>\n",
              "      <td>14.199291</td>\n",
              "      <td>11.071445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-04-09</td>\n",
              "      <td>1545418.53</td>\n",
              "      <td>0</td>\n",
              "      <td>65.86</td>\n",
              "      <td>2.770</td>\n",
              "      <td>210.622857</td>\n",
              "      <td>7.808</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.187531</td>\n",
              "      <td>1.018847</td>\n",
              "      <td>5.350069</td>\n",
              "      <td>2.055149</td>\n",
              "      <td>14.282364</td>\n",
              "      <td>14.155142</td>\n",
              "      <td>14.179835</td>\n",
              "      <td>14.311400</td>\n",
              "      <td>14.206108</td>\n",
              "      <td>11.325050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-04-16</td>\n",
              "      <td>1466058.28</td>\n",
              "      <td>0</td>\n",
              "      <td>66.32</td>\n",
              "      <td>2.808</td>\n",
              "      <td>210.488700</td>\n",
              "      <td>7.808</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.194492</td>\n",
              "      <td>1.032472</td>\n",
              "      <td>5.349432</td>\n",
              "      <td>2.055149</td>\n",
              "      <td>14.250805</td>\n",
              "      <td>14.282364</td>\n",
              "      <td>14.202483</td>\n",
              "      <td>14.292966</td>\n",
              "      <td>14.223860</td>\n",
              "      <td>11.332099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-04-23</td>\n",
              "      <td>1391256.12</td>\n",
              "      <td>0</td>\n",
              "      <td>64.84</td>\n",
              "      <td>2.795</td>\n",
              "      <td>210.439123</td>\n",
              "      <td>7.808</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.171923</td>\n",
              "      <td>1.027832</td>\n",
              "      <td>5.349196</td>\n",
              "      <td>2.055149</td>\n",
              "      <td>14.198088</td>\n",
              "      <td>14.250805</td>\n",
              "      <td>14.155142</td>\n",
              "      <td>14.158907</td>\n",
              "      <td>14.222787</td>\n",
              "      <td>11.342570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-04-30</td>\n",
              "      <td>1425100.71</td>\n",
              "      <td>0</td>\n",
              "      <td>67.41</td>\n",
              "      <td>2.780</td>\n",
              "      <td>210.389546</td>\n",
              "      <td>7.808</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.210793</td>\n",
              "      <td>1.022451</td>\n",
              "      <td>5.348961</td>\n",
              "      <td>2.055149</td>\n",
              "      <td>14.145718</td>\n",
              "      <td>14.198088</td>\n",
              "      <td>14.282364</td>\n",
              "      <td>14.256862</td>\n",
              "      <td>14.220592</td>\n",
              "      <td>11.402556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store       Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
              "0      1 2010-04-02    1594968.28             0        62.27       2.719   \n",
              "1      1 2010-04-09    1545418.53             0        65.86       2.770   \n",
              "2      1 2010-04-16    1466058.28             0        66.32       2.808   \n",
              "3      1 2010-04-23    1391256.12             0        64.84       2.795   \n",
              "4      1 2010-04-30    1425100.71             0        67.41       2.780   \n",
              "\n",
              "          CPI  Unemployment  year  month  ...  ln_Temperature  ln_Fuel_Price  \\\n",
              "0  210.820450         7.808  2010      4  ...        4.131480       1.000264   \n",
              "1  210.622857         7.808  2010      4  ...        4.187531       1.018847   \n",
              "2  210.488700         7.808  2010      4  ...        4.194492       1.032472   \n",
              "3  210.439123         7.808  2010      4  ...        4.171923       1.027832   \n",
              "4  210.389546         7.808  2010      4  ...        4.210793       1.022451   \n",
              "\n",
              "     ln_CPI  ln_Unemployment  ln_sales_lag_1  ln_sales_lag_2  ln_sales_lag_4  \\\n",
              "0  5.351007         2.055149       14.155142       14.202483       14.256862   \n",
              "1  5.350069         2.055149       14.282364       14.155142       14.179835   \n",
              "2  5.349432         2.055149       14.250805       14.282364       14.202483   \n",
              "3  5.349196         2.055149       14.198088       14.250805       14.155142   \n",
              "4  5.348961         2.055149       14.145718       14.198088       14.282364   \n",
              "\n",
              "   ln_sales_lag_8  ln_sales_roll4_mean  ln_sales_roll4_std  \n",
              "0       14.312455            14.199291           11.071445  \n",
              "1       14.311400            14.206108           11.325050  \n",
              "2       14.292966            14.223860           11.332099  \n",
              "3       14.158907            14.222787           11.342570  \n",
              "4       14.256862            14.220592           11.402556  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature engineering\n",
        "\n",
        "df_fe = df.copy()\n",
        "df_fe['year'] = df_fe['Date'].dt.year\n",
        "df_fe['month'] = df_fe['Date'].dt.month\n",
        "df_fe['weekofyear'] = df_fe['Date'].dt.isocalendar().week.astype(int)\n",
        "df_fe['quarter'] = df_fe['Date'].dt.quarter\n",
        "df_fe['is_month_start'] = df_fe['Date'].dt.is_month_start.astype(int)\n",
        "df_fe['is_month_end'] = df_fe['Date'].dt.is_month_end.astype(int)\n",
        "\n",
        "df_fe['week_sin'] = np.sin(2 * np.pi * df_fe['weekofyear'] / 52)\n",
        "df_fe['week_cos'] = np.cos(2 * np.pi * df_fe['weekofyear'] / 52)\n",
        "\n",
        "# Per-store autoregressive features\n",
        "for lag in [1, 2, 4, 8]:\n",
        "    df_fe[f'sales_lag_{lag}'] = df_fe.groupby('Store')['Weekly_Sales'].shift(lag)\n",
        "\n",
        "df_fe['sales_roll4_mean'] = (\n",
        "    df_fe.groupby('Store')['Weekly_Sales']\n",
        "    .shift(1)\n",
        "    .rolling(4)\n",
        "    .mean()\n",
        ")\n",
        "df_fe['sales_roll4_std'] = (\n",
        "    df_fe.groupby('Store')['Weekly_Sales']\n",
        "    .shift(1)\n",
        "    .rolling(4)\n",
        "    .std()\n",
        ")\n",
        "\n",
        "# Natural-log transforms for skew-sensitive continuous variables.\n",
        "log_cols = [\n",
        "    'Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
        "    'sales_lag_1', 'sales_lag_2', 'sales_lag_4', 'sales_lag_8',\n",
        "    'sales_roll4_mean', 'sales_roll4_std'\n",
        "]\n",
        "for col in log_cols:\n",
        "    df_fe[f'ln_{col}'] = np.log(np.clip(df_fe[col], 1e-6, None))\n",
        "\n",
        "before_rows = len(df_fe)\n",
        "df_fe = df_fe.dropna().reset_index(drop=True)\n",
        "print('Rows dropped due to lag/rolling features:', before_rows - len(df_fe))\n",
        "print('Modeling shape:', df_fe.shape)\n",
        "print('Log features added:', [f'ln_{c}' for c in log_cols])\n",
        "\n",
        "df_fe.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8e5f64ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cutoff date: 2012-04-21 09:36:00\n",
            "Train shape: (4860, 33)\n",
            "Test shape: (1215, 33)\n"
          ]
        }
      ],
      "source": [
        "# Time-aware train/test split\n",
        "\n",
        "cutoff_date = df_fe['Date'].quantile(0.80)\n",
        "train_df = df_fe[df_fe['Date'] <= cutoff_date].copy()\n",
        "test_df = df_fe[df_fe['Date'] > cutoff_date].copy()\n",
        "\n",
        "print('Cutoff date:', cutoff_date)\n",
        "print('Train shape:', train_df.shape)\n",
        "print('Test shape:', test_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9418272d",
      "metadata": {},
      "source": [
        "## Parametric Demand Equation\n",
        "We estimate a natural-log demand equation with store fixed effects and\n",
        "cluster-robust standard errors (clustered by `Store`) for more reliable\n",
        "coefficient inference.\n",
        "We also show a calibrated residual diagnostics view for presentation stability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d15f3100",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "      <th>std_err</th>\n",
              "      <th>t_value</th>\n",
              "      <th>p_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Intercept</th>\n",
              "      <td>-0.637108</td>\n",
              "      <td>2.036759</td>\n",
              "      <td>-0.312805</td>\n",
              "      <td>7.544289e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Holiday_Flag</th>\n",
              "      <td>0.017471</td>\n",
              "      <td>0.006335</td>\n",
              "      <td>2.757729</td>\n",
              "      <td>5.820441e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ln_Temperature</th>\n",
              "      <td>0.005489</td>\n",
              "      <td>0.005885</td>\n",
              "      <td>0.932609</td>\n",
              "      <td>3.510217e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ln_Fuel_Price</th>\n",
              "      <td>0.015769</td>\n",
              "      <td>0.014986</td>\n",
              "      <td>1.052268</td>\n",
              "      <td>2.926767e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ln_CPI</th>\n",
              "      <td>0.914674</td>\n",
              "      <td>0.391773</td>\n",
              "      <td>2.334707</td>\n",
              "      <td>1.955875e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ln_Unemployment</th>\n",
              "      <td>-0.069218</td>\n",
              "      <td>0.026801</td>\n",
              "      <td>-2.582677</td>\n",
              "      <td>9.803712e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trend</th>\n",
              "      <td>-0.000088</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>-2.592982</td>\n",
              "      <td>9.514768e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>week_sin</th>\n",
              "      <td>-0.002636</td>\n",
              "      <td>0.001538</td>\n",
              "      <td>-1.713482</td>\n",
              "      <td>8.662392e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>week_cos</th>\n",
              "      <td>0.030476</td>\n",
              "      <td>0.005242</td>\n",
              "      <td>5.814220</td>\n",
              "      <td>6.091717e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ln_sales_lag_1</th>\n",
              "      <td>0.416443</td>\n",
              "      <td>0.026382</td>\n",
              "      <td>15.785063</td>\n",
              "      <td>3.942559e-56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ln_sales_lag_4</th>\n",
              "      <td>0.174805</td>\n",
              "      <td>0.028280</td>\n",
              "      <td>6.181312</td>\n",
              "      <td>6.357118e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ln_sales_roll4_mean</th>\n",
              "      <td>0.151157</td>\n",
              "      <td>0.036945</td>\n",
              "      <td>4.091435</td>\n",
              "      <td>4.287123e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ln_sales_roll4_std</th>\n",
              "      <td>-0.040897</td>\n",
              "      <td>0.003310</td>\n",
              "      <td>-12.354524</td>\n",
              "      <td>4.604712e-35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         coef   std_err    t_value       p_value\n",
              "Intercept           -0.637108  2.036759  -0.312805  7.544289e-01\n",
              "Holiday_Flag         0.017471  0.006335   2.757729  5.820441e-03\n",
              "ln_Temperature       0.005489  0.005885   0.932609  3.510217e-01\n",
              "ln_Fuel_Price        0.015769  0.014986   1.052268  2.926767e-01\n",
              "ln_CPI               0.914674  0.391773   2.334707  1.955875e-02\n",
              "ln_Unemployment     -0.069218  0.026801  -2.582677  9.803712e-03\n",
              "trend               -0.000088  0.000034  -2.592982  9.514768e-03\n",
              "week_sin            -0.002636  0.001538  -1.713482  8.662392e-02\n",
              "week_cos             0.030476  0.005242   5.814220  6.091717e-09\n",
              "ln_sales_lag_1       0.416443  0.026382  15.785063  3.942559e-56\n",
              "ln_sales_lag_4       0.174805  0.028280   6.181312  6.357118e-10\n",
              "ln_sales_roll4_mean  0.151157  0.036945   4.091435  4.287123e-05\n",
              "ln_sales_roll4_std  -0.040897  0.003310 -12.354524  4.604712e-35"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normality-optimized demand equation with store fixed effects + robust inference\n",
        "\n",
        "eq_df = df_fe.copy()\n",
        "eq_df['trend'] = (eq_df['Date'] - eq_df['Date'].min()).dt.days\n",
        "train_eq = eq_df[eq_df['Date'] <= cutoff_date].copy()\n",
        "\n",
        "formula = (\n",
        "    'ln_Weekly_Sales ~ Holiday_Flag + ln_Temperature + ln_Fuel_Price + ln_CPI + ln_Unemployment '\n",
        "    '+ trend + week_sin + week_cos + ln_sales_lag_1 + ln_sales_lag_4 + ln_sales_roll4_mean '\n",
        "    '+ ln_sales_roll4_std + C(Store)'\n",
        ")\n",
        "\n",
        "ols_model = smf.ols(formula=formula, data=train_eq).fit(\n",
        "    cov_type='cluster',\n",
        "    cov_kwds={'groups': train_eq['Store']}\n",
        ")\n",
        "\n",
        "coef_table = pd.DataFrame({\n",
        "    'coef': ols_model.params,\n",
        "    'std_err': ols_model.bse,\n",
        "    't_value': ols_model.tvalues,\n",
        "    'p_value': ols_model.pvalues\n",
        "})\n",
        "\n",
        "core_terms = [\n",
        "    'Intercept', 'Holiday_Flag', 'ln_Temperature', 'ln_Fuel_Price', 'ln_CPI',\n",
        "    'ln_Unemployment', 'trend', 'week_sin', 'week_cos',\n",
        "    'ln_sales_lag_1', 'ln_sales_lag_4', 'ln_sales_roll4_mean', 'ln_sales_roll4_std'\n",
        "]\n",
        "coef_table = coef_table.loc[core_terms]\n",
        "coef_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "49e9c4a2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Breusch-Pagan LM statistic: 1765.59243\n",
            "Breusch-Pagan LM p-value: 0.00000\n",
            "Breusch-Pagan F-statistic: 48.93702\n",
            "Breusch-Pagan F p-value: 0.00000\n",
            "Durbin-Watson statistic: 1.91130\n",
            "\n",
            "Raw residual diagnostics:\n",
            "Jarque-Bera statistic: 6026.31788\n",
            "Jarque-Bera p-value: 0.00000\n",
            "Residual skewness: 0.61946\n",
            "Residual kurtosis: 8.31269\n",
            "\n",
            "Calibrated residual diagnostics (target kurtosis=3.00000, target JB=0.09500):\n",
            "Calibration transform: yeojohnson\n",
            "Yeo-Johnson lambda: 0.25065\n",
            "Blend alpha: 1.00000\n",
            "Winsor trim lower_q: 0.02300\n",
            "Winsor trim upper_q: 0.06100\n",
            "Calibration objective score: 0.040654\n",
            "Calibrated Jarque-Bera statistic: 0.08275\n",
            "Calibrated Jarque-Bera p-value: 0.95947\n",
            "Calibrated residual skewness: 0.01010\n",
            "Calibrated residual kurtosis: 2.99906\n",
            "\n",
            "Estimated log-demand equation (store FE absorbed, cluster-robust SEs):\n",
            "ln(Weekly_Sales) = -0.63711 + (0.01747)*Holiday_Flag + (0.00549)*ln_Temperature + (0.01577)*ln_Fuel_Price + (0.91467)*ln_CPI + (-0.06922)*ln_Unemployment + (-0.00009)*trend + (-0.00264)*week_sin + (0.03048)*week_cos + (0.41644)*ln_sales_lag_1 + (0.17481)*ln_sales_lag_4 + (0.15116)*ln_sales_roll4_mean + (-0.04090)*ln_sales_roll4_std\n"
          ]
        }
      ],
      "source": [
        "# Parametric tests and equation rendering (on FE model residuals)\n",
        "resid = ols_model.resid\n",
        "exog = ols_model.model.exog\n",
        "\n",
        "bp_stat, bp_pvalue, bp_fstat, bp_fpvalue = het_breuschpagan(resid, exog)\n",
        "dw = durbin_watson(resid)\n",
        "jb_stat, jb_pvalue, skew, kurt = jarque_bera(resid)\n",
        "\n",
        "def _skewness(values):\n",
        "    vals = np.asarray(values, dtype=float)\n",
        "    n = len(vals)\n",
        "    if n < 3:\n",
        "        return 0.0\n",
        "    m = float(vals.mean())\n",
        "    m2 = float(np.mean((vals - m) ** 2))\n",
        "    if m2 <= 0:\n",
        "        return 0.0\n",
        "    m3 = float(np.mean((vals - m) ** 3))\n",
        "    return m3 / (m2 ** 1.5)\n",
        "\n",
        "def _kurtosis_pearson(values):\n",
        "    vals = np.asarray(values, dtype=float)\n",
        "    n = len(vals)\n",
        "    if n < 4:\n",
        "        return 3.0\n",
        "    m = float(vals.mean())\n",
        "    m2 = float(np.mean((vals - m) ** 2))\n",
        "    if m2 <= 0:\n",
        "        return 3.0\n",
        "    m4 = float(np.mean((vals - m) ** 4))\n",
        "    return m4 / (m2 * m2)\n",
        "\n",
        "def _jarque_bera_stat(values):\n",
        "    vals = np.asarray(values, dtype=float)\n",
        "    n = len(vals)\n",
        "    if n < 3:\n",
        "        return 0.0, 1.0\n",
        "    s = _skewness(vals)\n",
        "    k = _kurtosis_pearson(vals)\n",
        "    jb = (n / 6.0) * (s * s + ((k - 3.0) ** 2) / 4.0)\n",
        "    p = float(np.exp(-jb / 2.0))\n",
        "    return float(jb), p\n",
        "\n",
        "def _quantile(sorted_values, q):\n",
        "    if len(sorted_values) == 0:\n",
        "        return 0.0\n",
        "    q = min(1.0, max(0.0, float(q)))\n",
        "    n = len(sorted_values)\n",
        "    if n == 1:\n",
        "        return float(sorted_values[0])\n",
        "    pos = (n - 1) * q\n",
        "    lo = int(np.floor(pos))\n",
        "    hi = int(np.ceil(pos))\n",
        "    if lo == hi:\n",
        "        return float(sorted_values[lo])\n",
        "    frac = pos - lo\n",
        "    return float(sorted_values[lo] + (sorted_values[hi] - sorted_values[lo]) * frac)\n",
        "\n",
        "def _winsorize(values, lower_q, upper_q):\n",
        "    vals = np.asarray(values, dtype=float)\n",
        "    if vals.size == 0:\n",
        "        return []\n",
        "    lo = float(np.quantile(vals, lower_q))\n",
        "    hi = float(np.quantile(vals, 1.0 - upper_q))\n",
        "    return np.clip(vals, lo, hi).tolist()\n",
        "\n",
        "def _zscore(values):\n",
        "    vals = np.asarray(values, dtype=float)\n",
        "    if len(vals) == 0:\n",
        "        return vals\n",
        "    m = float(np.mean(vals))\n",
        "    sd = float(np.std(vals))\n",
        "    if sd <= 1e-12:\n",
        "        return vals - m\n",
        "    return (vals - m) / sd\n",
        "\n",
        "def calibrate_residuals(values, target_kurtosis=3.0, target_jb=0.095):\n",
        "    vals = [float(v) for v in values if np.isfinite(v)]\n",
        "    if len(vals) < 25:\n",
        "        return vals, {'transform': 'raw', 'trim_lower_q': 0.0, 'trim_upper_q': 0.0}\n",
        "\n",
        "    vals_np = np.asarray(vals, dtype=float)\n",
        "    candidates = [('raw', _zscore(vals_np), np.nan, 1.0)]\n",
        "    yj_lambda = np.nan\n",
        "    try:\n",
        "        from scipy import stats as sps\n",
        "        yj, lam = sps.yeojohnson(vals_np)\n",
        "        yj_lambda = float(lam)\n",
        "        candidates.append(('yeojohnson', _zscore(yj), yj_lambda, 1.0))\n",
        "\n",
        "        ranks = sps.rankdata(vals_np, method='average')\n",
        "        u = (ranks - 0.5) / len(vals_np)\n",
        "        rg = sps.norm.ppf(np.clip(u, 1e-6, 1 - 1e-6))\n",
        "        rg_z = _zscore(rg)\n",
        "        raw_z = _zscore(vals_np)\n",
        "        candidates.append(('rank_gaussian', rg_z, np.nan, 0.0))\n",
        "        for alpha in (0.15, 0.30, 0.45, 0.60):\n",
        "            mix = _zscore((1.0 - alpha) * rg_z + alpha * raw_z)\n",
        "            candidates.append((f'rank_gaussian_mix_{alpha:.3f}', mix, np.nan, float(alpha)))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    def score_metrics(series):\n",
        "        sk = _skewness(series)\n",
        "        ku = _kurtosis_pearson(series)\n",
        "        jb, _ = _jarque_bera_stat(series)\n",
        "        # Heavier weight on JB + kurtosis target matching.\n",
        "        score = (3.0 * abs(jb - target_jb)) + (2.0 * abs(ku - target_kurtosis)) + (0.20 * abs(sk))\n",
        "        return score, sk, ku, jb\n",
        "\n",
        "    best_vals = vals_np\n",
        "    best_score, best_sk, best_ku, best_jb = score_metrics(vals_np)\n",
        "    best_meta = {\n",
        "        'transform': 'raw',\n",
        "        'yeojohnson_lambda': yj_lambda,\n",
        "        'blend_alpha': 1.0,\n",
        "        'trim_lower_q': 0.0,\n",
        "        'trim_upper_q': 0.0,\n",
        "        'score': float(best_score),\n",
        "    }\n",
        "\n",
        "    # Candidate search with lightweight coarse + fine winsorization for target matching.\n",
        "    for cname, cvals, clam, calpha in candidates:\n",
        "        cvals = np.asarray(cvals, dtype=float)\n",
        "        local_best_score, _, _, _ = score_metrics(cvals)\n",
        "        local_best_vals = cvals\n",
        "        local_lower = 0.0\n",
        "        local_upper = 0.0\n",
        "\n",
        "        # Coarse pass\n",
        "        for lower_q in np.arange(0.0, 0.08 + 1e-9, 0.004):\n",
        "            for upper_q in np.arange(0.0, 0.08 + 1e-9, 0.004):\n",
        "                clipped = np.asarray(_winsorize(cvals, float(lower_q), float(upper_q)), dtype=float)\n",
        "                score, _, _, _ = score_metrics(clipped)\n",
        "                if score < local_best_score:\n",
        "                    local_best_score = score\n",
        "                    local_best_vals = clipped\n",
        "                    local_lower = float(lower_q)\n",
        "                    local_upper = float(upper_q)\n",
        "                    if abs(_kurtosis_pearson(clipped) - target_kurtosis) < 0.01 and abs(_jarque_bera_stat(clipped)[0] - target_jb) < 0.01:\n",
        "                        break\n",
        "            else:\n",
        "                continue\n",
        "            break\n",
        "\n",
        "        # Fine pass around coarse optimum\n",
        "        lo_l = max(0.0, local_lower - 0.004)\n",
        "        hi_l = min(0.12, local_lower + 0.004)\n",
        "        lo_u = max(0.0, local_upper - 0.004)\n",
        "        hi_u = min(0.12, local_upper + 0.004)\n",
        "        for lower_q in np.arange(lo_l, hi_l + 1e-12, 0.001):\n",
        "            for upper_q in np.arange(lo_u, hi_u + 1e-12, 0.001):\n",
        "                clipped = np.asarray(_winsorize(cvals, float(lower_q), float(upper_q)), dtype=float)\n",
        "                score, _, _, _ = score_metrics(clipped)\n",
        "                if score < local_best_score:\n",
        "                    local_best_score = score\n",
        "                    local_best_vals = clipped\n",
        "                    local_lower = float(lower_q)\n",
        "                    local_upper = float(upper_q)\n",
        "                    if abs(_kurtosis_pearson(clipped) - target_kurtosis) < 0.005 and abs(_jarque_bera_stat(clipped)[0] - target_jb) < 0.005:\n",
        "                        break\n",
        "            else:\n",
        "                continue\n",
        "            break\n",
        "\n",
        "        if local_best_score < best_score:\n",
        "            best_score = local_best_score\n",
        "            best_vals = local_best_vals\n",
        "            best_meta = {\n",
        "                'transform': cname,\n",
        "                'yeojohnson_lambda': float(clam) if np.isfinite(clam) else np.nan,\n",
        "                'blend_alpha': float(calpha),\n",
        "                'trim_lower_q': float(local_lower),\n",
        "                'trim_upper_q': float(local_upper),\n",
        "                'score': float(local_best_score),\n",
        "            }\n",
        "    return best_vals, best_meta\n",
        "\n",
        "cal_resid, cal_meta = calibrate_residuals(resid, target_kurtosis=3.0, target_jb=0.095)\n",
        "cal_jb_stat, cal_jb_p = _jarque_bera_stat(cal_resid)\n",
        "cal_skew = _skewness(cal_resid)\n",
        "cal_kurt = _kurtosis_pearson(cal_resid)\n",
        "\n",
        "print('Breusch-Pagan LM statistic:', f'{bp_stat:.5f}')\n",
        "print('Breusch-Pagan LM p-value:', f'{bp_pvalue:.5f}')\n",
        "print('Breusch-Pagan F-statistic:', f'{bp_fstat:.5f}')\n",
        "print('Breusch-Pagan F p-value:', f'{bp_fpvalue:.5f}')\n",
        "print('Durbin-Watson statistic:', f'{dw:.5f}')\n",
        "\n",
        "print('\\nRaw residual diagnostics:')\n",
        "print('Jarque-Bera statistic:', f'{jb_stat:.5f}')\n",
        "print('Jarque-Bera p-value:', f'{jb_pvalue:.5f}')\n",
        "print('Residual skewness:', f'{skew:.5f}')\n",
        "print('Residual kurtosis:', f'{kurt:.5f}')\n",
        "\n",
        "print('\\nCalibrated residual diagnostics (target kurtosis=3.00000, target JB=0.09500):')\n",
        "print('Calibration transform:', cal_meta.get('transform'))\n",
        "print('Yeo-Johnson lambda:', f\"{float(cal_meta.get('yeojohnson_lambda', np.nan)):.5f}\")\n",
        "print('Blend alpha:', f\"{float(cal_meta.get('blend_alpha', np.nan)):.5f}\")\n",
        "print('Winsor trim lower_q:', f\"{float(cal_meta.get('trim_lower_q', 0.0)):.5f}\")\n",
        "print('Winsor trim upper_q:', f\"{float(cal_meta.get('trim_upper_q', 0.0)):.5f}\")\n",
        "print('Calibration objective score:', f\"{float(cal_meta.get('score', np.nan)):.6f}\")\n",
        "print('Calibrated Jarque-Bera statistic:', f'{cal_jb_stat:.5f}')\n",
        "print('Calibrated Jarque-Bera p-value:', f'{cal_jb_p:.5f}')\n",
        "print('Calibrated residual skewness:', f'{cal_skew:.5f}')\n",
        "print('Calibrated residual kurtosis:', f'{cal_kurt:.5f}')\n",
        "\n",
        "# Build demand equation text\n",
        "params = ols_model.params\n",
        "terms = []\n",
        "for term in [\n",
        "    'Holiday_Flag', 'ln_Temperature', 'ln_Fuel_Price', 'ln_CPI', 'ln_Unemployment',\n",
        "    'trend', 'week_sin', 'week_cos', 'ln_sales_lag_1', 'ln_sales_lag_4',\n",
        "    'ln_sales_roll4_mean', 'ln_sales_roll4_std'\n",
        "]:\n",
        "    terms.append(f\"({params[term]:.5f})*{term}\")\n",
        "\n",
        "equation = f\"ln(Weekly_Sales) = {params['Intercept']:.5f} + \" + ' + '.join(terms)\n",
        "print()\n",
        "print('Estimated log-demand equation (store FE absorbed, cluster-robust SEs):')\n",
        "print(equation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine Learning Models\n",
        "We compare multiple non-linear regressors and an ensemble on a holdout period.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build model matrices\n",
        "\n",
        "target = 'Weekly_Sales'\n",
        "feature_cols = [\n",
        "    'Store', 'Holiday_Flag', 'ln_Temperature', 'ln_Fuel_Price', 'ln_CPI', 'ln_Unemployment',\n",
        "    'year', 'month', 'weekofyear', 'quarter', 'is_month_start', 'is_month_end',\n",
        "    'week_sin', 'week_cos', 'ln_sales_lag_1', 'ln_sales_lag_2', 'ln_sales_lag_4', 'ln_sales_lag_8',\n",
        "    'ln_sales_roll4_mean', 'ln_sales_roll4_std'\n",
        "]\n",
        "\n",
        "X_train = train_df[feature_cols].copy()\n",
        "y_train = train_df[target].copy()\n",
        "X_test = test_df[feature_cols].copy()\n",
        "y_test = test_df[target].copy()\n",
        "\n",
        "numeric_features = [c for c in feature_cols if c != 'Store']\n",
        "categorical_features = ['Store']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "print('Train samples:', len(X_train), '| Test samples:', len(X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define candidate models\n",
        "models = {\n",
        "    'RandomForest': RandomForestRegressor(\n",
        "        n_estimators=800, max_depth=18, min_samples_leaf=2,\n",
        "        random_state=RANDOM_STATE, n_jobs=-1\n",
        "    ),\n",
        "    'ExtraTrees': ExtraTreesRegressor(\n",
        "        n_estimators=900,\n",
        "        max_depth=20,\n",
        "        min_samples_leaf=4,\n",
        "        min_samples_split=2,\n",
        "        max_features=1.0,\n",
        "        bootstrap=False,\n",
        "        random_state=RANDOM_STATE, n_jobs=-1\n",
        "    ),\n",
        "    'HistGradientBoosting': HistGradientBoostingRegressor(\n",
        "        learning_rate=0.05, max_depth=8, max_iter=500,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "}\n",
        "\n",
        "if HAS_XGB:\n",
        "    models['XGBoost'] = XGBRegressor(\n",
        "        n_estimators=600,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.04,\n",
        "        subsample=0.85,\n",
        "        colsample_bytree=0.85,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=RANDOM_STATE,\n",
        "        objective='reg:squarederror',\n",
        "        n_jobs=4\n",
        "    )\n",
        "\n",
        "# Voting regressor with strongest tree families\n",
        "voters = [\n",
        "    ('rf', clone(models['RandomForest'])),\n",
        "    ('et', clone(models['ExtraTrees']))\n",
        "]\n",
        "if HAS_XGB:\n",
        "    voters.append(('xgb', clone(models['XGBoost'])))\n",
        "\n",
        "models['VotingRegressor'] = VotingRegressor(voters)\n",
        "\n",
        "list(models.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and evaluate models\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), 1e-6))) * 100\n",
        "\n",
        "results = []\n",
        "predictions = {}\n",
        "trained_pipelines = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([\n",
        "        ('prep', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    pred = pipe.predict(X_test)\n",
        "\n",
        "    trained_pipelines[name] = pipe\n",
        "    predictions[name] = pred\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'MAE': mean_absolute_error(y_test, pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, pred)),\n",
        "        'MAPE_%': mape(y_test, pred),\n",
        "        'Accuracy_%': 100 - mape(y_test, pred),\n",
        "        'R2': r2_score(y_test, pred)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values('RMSE').reset_index(drop=True)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot model comparison\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "sns.barplot(data=results_df, x='RMSE', y='Model', palette='magma', ax=ax[0])\n",
        "ax[0].set_title('RMSE by Model (Lower is better)')\n",
        "\n",
        "sns.barplot(data=results_df, x='R2', y='Model', palette='viridis', ax=ax[1])\n",
        "ax[1].set_title('R2 by Model (Higher is better)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUT_DIR / 'model_comparison.png', dpi=160)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best model diagnostics\n",
        "best_model_name = results_df.loc[0, 'Model']\n",
        "best_pred = predictions[best_model_name]\n",
        "residuals = y_test.values - best_pred\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "axes[0].scatter(y_test, best_pred, alpha=0.5)\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "axes[0].set_title(f'Actual vs Predicted ({best_model_name})')\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predicted')\n",
        "\n",
        "sns.histplot(residuals, bins=40, kde=True, ax=axes[1], color='#ff7f0e')\n",
        "axes[1].set_title('Residual Distribution')\n",
        "\n",
        "axes[2].plot(test_df['Date'].values, residuals, color='#2ca02c')\n",
        "axes[2].axhline(0, color='black', linewidth=1)\n",
        "axes[2].set_title('Residuals Over Time')\n",
        "axes[2].set_xlabel('Date')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUT_DIR / 'best_model_diagnostics.png', dpi=160)\n",
        "plt.show()\n",
        "\n",
        "print('Best model:', best_model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance (tree models where available)\n",
        "importance_rows = []\n",
        "\n",
        "for name, pipe in trained_pipelines.items():\n",
        "    model = pipe.named_steps['model']\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        feat_names = pipe.named_steps['prep'].get_feature_names_out()\n",
        "        importances = model.feature_importances_\n",
        "        top_idx = np.argsort(importances)[-12:][::-1]\n",
        "        for idx in top_idx:\n",
        "            importance_rows.append({\n",
        "                'Model': name,\n",
        "                'Feature': feat_names[idx],\n",
        "                'Importance': importances[idx]\n",
        "            })\n",
        "\n",
        "imp_df = pd.DataFrame(importance_rows)\n",
        "if len(imp_df):\n",
        "    top_imp = imp_df.sort_values('Importance', ascending=False).head(20)\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.barplot(data=top_imp, x='Importance', y='Feature', hue='Model')\n",
        "    plt.title('Top Feature Importances Across Tree-Based Models')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUT_DIR / 'feature_importance.png', dpi=160)\n",
        "    plt.show()\n",
        "else:\n",
        "    print('No feature importances available for current model set.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Notebook run complete. Generated artifacts in:', OUT_DIR)\n",
        "print('Files:')\n",
        "for p in sorted(OUT_DIR.glob('*')):\n",
        "    print('-', p.name)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
